{"trial_data": [["{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"13a3ca1f\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059527030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c2274756e652d646565707374796c6f6d657472792d3531322d73652d64656661756c74948c0e747269616c5f6469725f6e616d65948c96747261696e5f74756e655f31336133636131665f315f616363756d756c6174655f677261645f626174636865733d342c62657461733d305f375f305f3939392c636865636b5f76616c5f65766572795f6e5f65706f63683d4e6f6e652c636865636b706f696e745f6d65747269633d76616c5f746f74616c5f6c6f73732c636865635f323032352d30372d31345f31382d30302d3337948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e74948875628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c342f736372617463682f666b756c756d62612f446565705374796c6f6d657472792f736372697074732f2e2e2f7261795f6c6f6773948c0673796e6365729468008c115f46696c6573797374656d53796e6365729493942981947d94286815681b68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d30372d31345f31382d30302d33369475622e\"\n  },\n  \"config\": {\n    \"mode\": \"tune\",\n    \"project_name\": \"deep-stylometry\",\n    \"group_name\": \"tune-deepstylometry-512-se-default\",\n    \"do_train\": true,\n    \"do_test\": false,\n    \"_execution_config\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 4.73e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-09,\n      \"weight_decay\": 0.09,\n      \"num_cycles\": 0.5,\n      \"early_stopping\": false,\n      \"early_stopping_metric\": null,\n      \"early_stopping_mode\": null,\n      \"early_stopping_patience\": 3,\n      \"checkpoint_metric\": \"val_total_loss\",\n      \"checkpoint_mode\": \"min\",\n      \"save_top_k\": 2,\n      \"device\": \"gpu\",\n      \"num_devices\": 3,\n      \"strategy\": \"ddp_find_unused_parameters_true\",\n      \"max_steps\": -1,\n      \"max_epochs\": 4,\n      \"val_check_interval\": null,\n      \"check_val_every_n_epoch\": null,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"use_wandb\": true,\n      \"log_model\": true,\n      \"watch\": \"gradients\"\n    },\n    \"data\": {\n      \"ds_name\": \"se\",\n      \"batch_size\": 16,\n      \"tokenizer_name\": \"FacebookAI/roberta-base\",\n      \"max_length\": 512,\n      \"map_batch_size\": 1000,\n      \"load_from_cache_file\": true,\n      \"config_name\": null,\n      \"mlm_collator\": false\n    },\n    \"model\": {\n      \"base_model_name\": \"FacebookAI/roberta-base\",\n      \"is_decoder_model\": false,\n      \"add_linear_layers\": true,\n      \"dropout\": 0.1,\n      \"contrastive_temp\": 0.27922426342871626,\n      \"pooling_method\": \"li\",\n      \"distance_weightning\": \"exp\",\n      \"alpha\": 0.32436397316385956,\n      \"use_softmax\": true,\n      \"initial_gumbel_temp\": null,\n      \"auto_anneal_gumbel\": true,\n      \"min_gumbel_temp\": 0.5\n    },\n    \"_train\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 4.73e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-09,\n      \"weight_decay\": 0.09,\n      \"num_cycles\": 0.5,\n      \"early_stopping\": false,\n      \"early_stopping_metric\": null,\n      \"early_stopping_mode\": null,\n      \"early_stopping_patience\": 3,\n      \"checkpoint_metric\": \"val_total_loss\",\n      \"checkpoint_mode\": \"min\",\n      \"save_top_k\": 2,\n      \"device\": \"gpu\",\n      \"num_devices\": 3,\n      \"strategy\": \"ddp_find_unused_parameters_true\",\n      \"max_steps\": -1,\n      \"max_epochs\": 4,\n      \"val_check_interval\": null,\n      \"check_val_every_n_epoch\": null,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"use_wandb\": true,\n      \"log_model\": true,\n      \"watch\": \"gradients\"\n    },\n    \"_tune\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 7.871594481686971e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-07,\n      \"weight_decay\": 0.08429170041256055,\n      \"num_cycles\": 0.5,\n      \"device\": \"gpu\",\n      \"num_devices_per_trial\": 1,\n      \"num_cpus_per_trial\": 10,\n      \"max_steps\": -1,\n      \"max_epochs\": 3,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"metric\": \"val_total_loss\",\n      \"mode\": \"min\",\n      \"num_samples\": 30,\n      \"max_concurrent_trials\": 3,\n      \"time_budget_s\": 151200,\n      \"max_t\": 3,\n      \"use_wandb\": true\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"mode\": \"tune\",\n    \"project_name\": \"deep-stylometry\",\n    \"group_name\": \"tune-deepstylometry-512-se-default\",\n    \"do_train\": true,\n    \"do_test\": false,\n    \"_execution_config\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 4.73e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-09,\n      \"weight_decay\": 0.09,\n      \"num_cycles\": 0.5,\n      \"early_stopping\": false,\n      \"early_stopping_metric\": null,\n      \"early_stopping_mode\": null,\n      \"early_stopping_patience\": 3,\n      \"checkpoint_metric\": \"val_total_loss\",\n      \"checkpoint_mode\": \"min\",\n      \"save_top_k\": 2,\n      \"device\": \"gpu\",\n      \"num_devices\": 3,\n      \"strategy\": \"ddp_find_unused_parameters_true\",\n      \"max_steps\": -1,\n      \"max_epochs\": 4,\n      \"val_check_interval\": null,\n      \"check_val_every_n_epoch\": null,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"use_wandb\": true,\n      \"log_model\": true,\n      \"watch\": \"gradients\"\n    },\n    \"data\": {\n      \"ds_name\": \"se\",\n      \"batch_size\": 16,\n      \"tokenizer_name\": \"FacebookAI/roberta-base\",\n      \"max_length\": 512,\n      \"map_batch_size\": 1000,\n      \"load_from_cache_file\": true,\n      \"config_name\": null,\n      \"mlm_collator\": false\n    },\n    \"model\": {\n      \"base_model_name\": \"FacebookAI/roberta-base\",\n      \"is_decoder_model\": false,\n      \"add_linear_layers\": true,\n      \"dropout\": 0.1,\n      \"contrastive_temp\": 0.27922426342871626,\n      \"pooling_method\": \"li\",\n      \"distance_weightning\": \"exp\",\n      \"alpha\": 0.32436397316385956,\n      \"use_softmax\": true,\n      \"initial_gumbel_temp\": null,\n      \"auto_anneal_gumbel\": true,\n      \"min_gumbel_temp\": 0.5\n    },\n    \"_train\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 4.73e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-09,\n      \"weight_decay\": 0.09,\n      \"num_cycles\": 0.5,\n      \"early_stopping\": false,\n      \"early_stopping_metric\": null,\n      \"early_stopping_mode\": null,\n      \"early_stopping_patience\": 3,\n      \"checkpoint_metric\": \"val_total_loss\",\n      \"checkpoint_mode\": \"min\",\n      \"save_top_k\": 2,\n      \"device\": \"gpu\",\n      \"num_devices\": 3,\n      \"strategy\": \"ddp_find_unused_parameters_true\",\n      \"max_steps\": -1,\n      \"max_epochs\": 4,\n      \"val_check_interval\": null,\n      \"check_val_every_n_epoch\": null,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"use_wandb\": true,\n      \"log_model\": true,\n      \"watch\": \"gradients\"\n    },\n    \"_tune\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 7.871594481686971e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-07,\n      \"weight_decay\": 0.08429170041256055,\n      \"num_cycles\": 0.5,\n      \"device\": \"gpu\",\n      \"num_devices_per_trial\": 1,\n      \"num_cpus_per_trial\": 10,\n      \"max_steps\": -1,\n      \"max_epochs\": 3,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"metric\": \"val_total_loss\",\n      \"mode\": \"min\",\n      \"num_samples\": 30,\n      \"max_concurrent_trials\": 3,\n      \"time_budget_s\": 151200,\n      \"max_t\": 3,\n      \"use_wandb\": true\n    }\n  },\n  \"evaluated_params\": {\n    \"do_test\": false,\n    \"do_train\": true,\n    \"group_name\": \"tune-deepstylometry-512-se-default\",\n    \"mode\": \"tune\",\n    \"project_name\": \"deep-stylometry\",\n    \"_execution_config/accumulate_grad_batches\": 4,\n    \"_execution_config/betas\": [\n      0.7,\n      0.999\n    ],\n    \"_execution_config/check_val_every_n_epoch\": null,\n    \"_execution_config/checkpoint_metric\": \"val_total_loss\",\n    \"_execution_config/checkpoint_mode\": \"min\",\n    \"_execution_config/device\": \"gpu\",\n    \"_execution_config/early_stopping\": false,\n    \"_execution_config/early_stopping_metric\": null,\n    \"_execution_config/early_stopping_mode\": null,\n    \"_execution_config/early_stopping_patience\": 3,\n    \"_execution_config/eps\": 1e-09,\n    \"_execution_config/gradient_clip_val\": null,\n    \"_execution_config/lm_loss_weight\": 0.0,\n    \"_execution_config/log_every_n_steps\": 1,\n    \"_execution_config/log_model\": true,\n    \"_execution_config/loss\": \"info_nce\",\n    \"_execution_config/lr\": 4.73e-05,\n    \"_execution_config/margin\": null,\n    \"_execution_config/max_epochs\": 4,\n    \"_execution_config/max_steps\": -1,\n    \"_execution_config/num_cycles\": 0.5,\n    \"_execution_config/num_devices\": 3,\n    \"_execution_config/precision\": \"32\",\n    \"_execution_config/save_top_k\": 2,\n    \"_execution_config/strategy\": \"ddp_find_unused_parameters_true\",\n    \"_execution_config/use_wandb\": true,\n    \"_execution_config/val_check_interval\": null,\n    \"_execution_config/watch\": \"gradients\",\n    \"_execution_config/weight_decay\": 0.09,\n    \"_train/accumulate_grad_batches\": 4,\n    \"_train/betas\": [\n      0.7,\n      0.999\n    ],\n    \"_train/check_val_every_n_epoch\": null,\n    \"_train/checkpoint_metric\": \"val_total_loss\",\n    \"_train/checkpoint_mode\": \"min\",\n    \"_train/device\": \"gpu\",\n    \"_train/early_stopping\": false,\n    \"_train/early_stopping_metric\": null,\n    \"_train/early_stopping_mode\": null,\n    \"_train/early_stopping_patience\": 3,\n    \"_train/eps\": 1e-09,\n    \"_train/gradient_clip_val\": null,\n    \"_train/lm_loss_weight\": 0.0,\n    \"_train/log_every_n_steps\": 1,\n    \"_train/log_model\": true,\n    \"_train/loss\": \"info_nce\",\n    \"_train/lr\": 4.73e-05,\n    \"_train/margin\": null,\n    \"_train/max_epochs\": 4,\n    \"_train/max_steps\": -1,\n    \"_train/num_cycles\": 0.5,\n    \"_train/num_devices\": 3,\n    \"_train/precision\": \"32\",\n    \"_train/save_top_k\": 2,\n    \"_train/strategy\": \"ddp_find_unused_parameters_true\",\n    \"_train/use_wandb\": true,\n    \"_train/val_check_interval\": null,\n    \"_train/watch\": \"gradients\",\n    \"_train/weight_decay\": 0.09,\n    \"_tune/accumulate_grad_batches\": 4,\n    \"_tune/betas\": [\n      0.7,\n      0.999\n    ],\n    \"_tune/device\": \"gpu\",\n    \"_tune/eps\": 1e-07,\n    \"_tune/gradient_clip_val\": null,\n    \"_tune/lm_loss_weight\": 0.0,\n    \"_tune/log_every_n_steps\": 1,\n    \"_tune/loss\": \"info_nce\",\n    \"_tune/lr\": 7.871594481686971e-05,\n    \"_tune/margin\": null,\n    \"_tune/max_concurrent_trials\": 3,\n    \"_tune/max_epochs\": 3,\n    \"_tune/max_steps\": -1,\n    \"_tune/max_t\": 3,\n    \"_tune/metric\": \"val_total_loss\",\n    \"_tune/mode\": \"min\",\n    \"_tune/num_cpus_per_trial\": 10,\n    \"_tune/num_cycles\": 0.5,\n    \"_tune/num_devices_per_trial\": 1,\n    \"_tune/num_samples\": 30,\n    \"_tune/precision\": \"32\",\n    \"_tune/time_budget_s\": 151200,\n    \"_tune/use_wandb\": true,\n    \"_tune/weight_decay\": 0.08429170041256055,\n    \"data/batch_size\": 16,\n    \"data/config_name\": null,\n    \"data/ds_name\": \"se\",\n    \"data/load_from_cache_file\": true,\n    \"data/map_batch_size\": 1000,\n    \"data/max_length\": 512,\n    \"data/mlm_collator\": false,\n    \"data/tokenizer_name\": \"FacebookAI/roberta-base\",\n    \"model/add_linear_layers\": true,\n    \"model/alpha\": 0.32436397316385956,\n    \"model/auto_anneal_gumbel\": true,\n    \"model/base_model_name\": \"FacebookAI/roberta-base\",\n    \"model/contrastive_temp\": 0.27922426342871626,\n    \"model/distance_weightning\": \"exp\",\n    \"model/dropout\": 0.1,\n    \"model/initial_gumbel_temp\": null,\n    \"model/is_decoder_model\": false,\n    \"model/min_gumbel_temp\": 0.5,\n    \"model/pooling_method\": \"li\",\n    \"model/use_softmax\": true\n  },\n  \"experiment_tag\": \"1_accumulate_grad_batches=4,betas=0_7_0_999,check_val_every_n_epoch=None,checkpoint_metric=val_total_loss,checkpoint_mode=min,device=gpu,early_stopping=False,early_stopping_metric=None,early_stopping_mode=None,early_stopping_patience=3,eps=0.0000,gradient_clip_val=None,lm_loss_weight=0.0000,log_every_n_steps=1,log_model=True,loss=info_nce,lr=0.0000,margin=None,max_epochs=4,max_steps=-1,num_cycles=0.5000,num_devices=3,precision=32,save_top_k=2,strategy=ddp_find_unused_parameters_true,use_wandb=True,val_check_interval=None,watch=gradients,weight_decay=0.0900,accumulate_grad_batches=4,betas=0_7_0_999,check_val_every_n_epoch=None,checkpoint_metric=val_total_loss,checkpoint_mode=min,device=gpu,early_stopping=False,early_stopping_metric=None,early_stopping_mode=None,early_stopping_patience=3,eps=0.0000,gradient_clip_val=None,lm_loss_weight=0.0000,log_every_n_steps=1,log_model=True,loss=info_nce,lr=0.0000,margin=None,max_epochs=4,max_steps=-1,num_cycles=0.5000,num_devices=3,precision=32,save_top_k=2,strategy=ddp_find_unused_parameters_true,use_wandb=True,val_check_interval=None,watch=gradients,weight_decay=0.0900,accumulate_grad_batches=4,betas=0_7_0_999,device=gpu,eps=0.0000,gradient_clip_val=None,lm_loss_weight=0.0000,log_every_n_steps=1,loss=info_nce,lr=0.0001,margin=None,max_concurrent_trials=3,max_epochs=3,max_steps=-1,max_t=3,metric=val_total_loss,mode=min,num_cpus_per_trial=10,num_cycles=0.5000,num_devices_per_trial=1,num_samples=30,precision=32,time_budget_s=151200,use_wandb=True,weight_decay=0.0843,batch_size=16,config_name=None,ds_name=se,load_from_cache_file=True,map_batch_size=1000,max_length=512,mlm_collator=False,tokenizer_name=FacebookAI_roberta-base,do_test=False,do_train=True,group_name=tune-deepstylometry-512-se-default,mode=tune,add_linear_layers=True,alpha=0.3244,auto_anneal_gumbel=True,base_model_name=FacebookAI_roberta-base,contrastive_temp=0.2792,distance_weightning=exp,dropout=0.1000,initial_gumbel_temp=None,is_decoder_model=False,min_gumbel_temp=0.5000,pooling_method=li,use_softmax=True,project_name=deep-stylometry\",\n  \"stopping_criterion\": {\n    \"completed_epoch\": 3\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740400000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"relative_logdir\": \"train_tune_13a3ca1f_1_accumulate_grad_batches=4,betas=0_7_0_999,check_val_every_n_epoch=None,checkpoint_metric=val_total_loss,chec_2025-07-14_18-00-37\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1752508848.080612,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"trial_id\": \"13a3ca1f\"\n  },\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b018c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"4a24f8a5\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"mode\": \"tune\",\n    \"project_name\": \"deep-stylometry\",\n    \"group_name\": \"tune-deepstylometry-512-se-default\",\n    \"do_train\": true,\n    \"do_test\": false,\n    \"_execution_config\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 4.73e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-09,\n      \"weight_decay\": 0.09,\n      \"num_cycles\": 0.5,\n      \"early_stopping\": false,\n      \"early_stopping_metric\": null,\n      \"early_stopping_mode\": null,\n      \"early_stopping_patience\": 3,\n      \"checkpoint_metric\": \"val_total_loss\",\n      \"checkpoint_mode\": \"min\",\n      \"save_top_k\": 2,\n      \"device\": \"gpu\",\n      \"num_devices\": 3,\n      \"strategy\": \"ddp_find_unused_parameters_true\",\n      \"max_steps\": -1,\n      \"max_epochs\": 4,\n      \"val_check_interval\": null,\n      \"check_val_every_n_epoch\": null,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"use_wandb\": true,\n      \"log_model\": true,\n      \"watch\": \"gradients\"\n    },\n    \"data\": {\n      \"ds_name\": \"se\",\n      \"batch_size\": 16,\n      \"tokenizer_name\": \"FacebookAI/roberta-base\",\n      \"max_length\": 512,\n      \"map_batch_size\": 1000,\n      \"load_from_cache_file\": true,\n      \"config_name\": null,\n      \"mlm_collator\": false\n    },\n    \"model\": {\n      \"base_model_name\": \"FacebookAI/roberta-base\",\n      \"is_decoder_model\": false,\n      \"add_linear_layers\": true,\n      \"dropout\": 0.1,\n      \"contrastive_temp\": 0.288440067739198,\n      \"pooling_method\": \"li\",\n      \"distance_weightning\": \"none\",\n      \"alpha\": 0.4029584028948178,\n      \"use_softmax\": true,\n      \"initial_gumbel_temp\": null,\n      \"auto_anneal_gumbel\": true,\n      \"min_gumbel_temp\": 0.5\n    },\n    \"_train\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 4.73e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-09,\n      \"weight_decay\": 0.09,\n      \"num_cycles\": 0.5,\n      \"early_stopping\": false,\n      \"early_stopping_metric\": null,\n      \"early_stopping_mode\": null,\n      \"early_stopping_patience\": 3,\n      \"checkpoint_metric\": \"val_total_loss\",\n      \"checkpoint_mode\": \"min\",\n      \"save_top_k\": 2,\n      \"device\": \"gpu\",\n      \"num_devices\": 3,\n      \"strategy\": \"ddp_find_unused_parameters_true\",\n      \"max_steps\": -1,\n      \"max_epochs\": 4,\n      \"val_check_interval\": null,\n      \"check_val_every_n_epoch\": null,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"use_wandb\": true,\n      \"log_model\": true,\n      \"watch\": \"gradients\"\n    },\n    \"_tune\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 1.7887550890401876e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-08,\n      \"weight_decay\": 0.05039386210370244,\n      \"num_cycles\": 0.5,\n      \"device\": \"gpu\",\n      \"num_devices_per_trial\": 1,\n      \"num_cpus_per_trial\": 10,\n      \"max_steps\": -1,\n      \"max_epochs\": 3,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"metric\": \"val_total_loss\",\n      \"mode\": \"min\",\n      \"num_samples\": 30,\n      \"max_concurrent_trials\": 3,\n      \"time_budget_s\": 151200,\n      \"max_t\": 3,\n      \"use_wandb\": true\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"mode\": \"tune\",\n    \"project_name\": \"deep-stylometry\",\n    \"group_name\": \"tune-deepstylometry-512-se-default\",\n    \"do_train\": true,\n    \"do_test\": false,\n    \"_execution_config\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 4.73e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-09,\n      \"weight_decay\": 0.09,\n      \"num_cycles\": 0.5,\n      \"early_stopping\": false,\n      \"early_stopping_metric\": null,\n      \"early_stopping_mode\": null,\n      \"early_stopping_patience\": 3,\n      \"checkpoint_metric\": \"val_total_loss\",\n      \"checkpoint_mode\": \"min\",\n      \"save_top_k\": 2,\n      \"device\": \"gpu\",\n      \"num_devices\": 3,\n      \"strategy\": \"ddp_find_unused_parameters_true\",\n      \"max_steps\": -1,\n      \"max_epochs\": 4,\n      \"val_check_interval\": null,\n      \"check_val_every_n_epoch\": null,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"use_wandb\": true,\n      \"log_model\": true,\n      \"watch\": \"gradients\"\n    },\n    \"data\": {\n      \"ds_name\": \"se\",\n      \"batch_size\": 16,\n      \"tokenizer_name\": \"FacebookAI/roberta-base\",\n      \"max_length\": 512,\n      \"map_batch_size\": 1000,\n      \"load_from_cache_file\": true,\n      \"config_name\": null,\n      \"mlm_collator\": false\n    },\n    \"model\": {\n      \"base_model_name\": \"FacebookAI/roberta-base\",\n      \"is_decoder_model\": false,\n      \"add_linear_layers\": true,\n      \"dropout\": 0.1,\n      \"contrastive_temp\": 0.288440067739198,\n      \"pooling_method\": \"li\",\n      \"distance_weightning\": \"none\",\n      \"alpha\": 0.4029584028948178,\n      \"use_softmax\": true,\n      \"initial_gumbel_temp\": null,\n      \"auto_anneal_gumbel\": true,\n      \"min_gumbel_temp\": 0.5\n    },\n    \"_train\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 4.73e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-09,\n      \"weight_decay\": 0.09,\n      \"num_cycles\": 0.5,\n      \"early_stopping\": false,\n      \"early_stopping_metric\": null,\n      \"early_stopping_mode\": null,\n      \"early_stopping_patience\": 3,\n      \"checkpoint_metric\": \"val_total_loss\",\n      \"checkpoint_mode\": \"min\",\n      \"save_top_k\": 2,\n      \"device\": \"gpu\",\n      \"num_devices\": 3,\n      \"strategy\": \"ddp_find_unused_parameters_true\",\n      \"max_steps\": -1,\n      \"max_epochs\": 4,\n      \"val_check_interval\": null,\n      \"check_val_every_n_epoch\": null,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"use_wandb\": true,\n      \"log_model\": true,\n      \"watch\": \"gradients\"\n    },\n    \"_tune\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 1.7887550890401876e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-08,\n      \"weight_decay\": 0.05039386210370244,\n      \"num_cycles\": 0.5,\n      \"device\": \"gpu\",\n      \"num_devices_per_trial\": 1,\n      \"num_cpus_per_trial\": 10,\n      \"max_steps\": -1,\n      \"max_epochs\": 3,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"metric\": \"val_total_loss\",\n      \"mode\": \"min\",\n      \"num_samples\": 30,\n      \"max_concurrent_trials\": 3,\n      \"time_budget_s\": 151200,\n      \"max_t\": 3,\n      \"use_wandb\": true\n    }\n  },\n  \"evaluated_params\": {\n    \"do_test\": false,\n    \"do_train\": true,\n    \"group_name\": \"tune-deepstylometry-512-se-default\",\n    \"mode\": \"tune\",\n    \"project_name\": \"deep-stylometry\",\n    \"_execution_config/accumulate_grad_batches\": 4,\n    \"_execution_config/betas\": [\n      0.7,\n      0.999\n    ],\n    \"_execution_config/check_val_every_n_epoch\": null,\n    \"_execution_config/checkpoint_metric\": \"val_total_loss\",\n    \"_execution_config/checkpoint_mode\": \"min\",\n    \"_execution_config/device\": \"gpu\",\n    \"_execution_config/early_stopping\": false,\n    \"_execution_config/early_stopping_metric\": null,\n    \"_execution_config/early_stopping_mode\": null,\n    \"_execution_config/early_stopping_patience\": 3,\n    \"_execution_config/eps\": 1e-09,\n    \"_execution_config/gradient_clip_val\": null,\n    \"_execution_config/lm_loss_weight\": 0.0,\n    \"_execution_config/log_every_n_steps\": 1,\n    \"_execution_config/log_model\": true,\n    \"_execution_config/loss\": \"info_nce\",\n    \"_execution_config/lr\": 4.73e-05,\n    \"_execution_config/margin\": null,\n    \"_execution_config/max_epochs\": 4,\n    \"_execution_config/max_steps\": -1,\n    \"_execution_config/num_cycles\": 0.5,\n    \"_execution_config/num_devices\": 3,\n    \"_execution_config/precision\": \"32\",\n    \"_execution_config/save_top_k\": 2,\n    \"_execution_config/strategy\": \"ddp_find_unused_parameters_true\",\n    \"_execution_config/use_wandb\": true,\n    \"_execution_config/val_check_interval\": null,\n    \"_execution_config/watch\": \"gradients\",\n    \"_execution_config/weight_decay\": 0.09,\n    \"_train/accumulate_grad_batches\": 4,\n    \"_train/betas\": [\n      0.7,\n      0.999\n    ],\n    \"_train/check_val_every_n_epoch\": null,\n    \"_train/checkpoint_metric\": \"val_total_loss\",\n    \"_train/checkpoint_mode\": \"min\",\n    \"_train/device\": \"gpu\",\n    \"_train/early_stopping\": false,\n    \"_train/early_stopping_metric\": null,\n    \"_train/early_stopping_mode\": null,\n    \"_train/early_stopping_patience\": 3,\n    \"_train/eps\": 1e-09,\n    \"_train/gradient_clip_val\": null,\n    \"_train/lm_loss_weight\": 0.0,\n    \"_train/log_every_n_steps\": 1,\n    \"_train/log_model\": true,\n    \"_train/loss\": \"info_nce\",\n    \"_train/lr\": 4.73e-05,\n    \"_train/margin\": null,\n    \"_train/max_epochs\": 4,\n    \"_train/max_steps\": -1,\n    \"_train/num_cycles\": 0.5,\n    \"_train/num_devices\": 3,\n    \"_train/precision\": \"32\",\n    \"_train/save_top_k\": 2,\n    \"_train/strategy\": \"ddp_find_unused_parameters_true\",\n    \"_train/use_wandb\": true,\n    \"_train/val_check_interval\": null,\n    \"_train/watch\": \"gradients\",\n    \"_train/weight_decay\": 0.09,\n    \"_tune/accumulate_grad_batches\": 4,\n    \"_tune/betas\": [\n      0.7,\n      0.999\n    ],\n    \"_tune/device\": \"gpu\",\n    \"_tune/eps\": 1e-08,\n    \"_tune/gradient_clip_val\": null,\n    \"_tune/lm_loss_weight\": 0.0,\n    \"_tune/log_every_n_steps\": 1,\n    \"_tune/loss\": \"info_nce\",\n    \"_tune/lr\": 1.7887550890401876e-05,\n    \"_tune/margin\": null,\n    \"_tune/max_concurrent_trials\": 3,\n    \"_tune/max_epochs\": 3,\n    \"_tune/max_steps\": -1,\n    \"_tune/max_t\": 3,\n    \"_tune/metric\": \"val_total_loss\",\n    \"_tune/mode\": \"min\",\n    \"_tune/num_cpus_per_trial\": 10,\n    \"_tune/num_cycles\": 0.5,\n    \"_tune/num_devices_per_trial\": 1,\n    \"_tune/num_samples\": 30,\n    \"_tune/precision\": \"32\",\n    \"_tune/time_budget_s\": 151200,\n    \"_tune/use_wandb\": true,\n    \"_tune/weight_decay\": 0.05039386210370244,\n    \"data/batch_size\": 16,\n    \"data/config_name\": null,\n    \"data/ds_name\": \"se\",\n    \"data/load_from_cache_file\": true,\n    \"data/map_batch_size\": 1000,\n    \"data/max_length\": 512,\n    \"data/mlm_collator\": false,\n    \"data/tokenizer_name\": \"FacebookAI/roberta-base\",\n    \"model/add_linear_layers\": true,\n    \"model/alpha\": 0.4029584028948178,\n    \"model/auto_anneal_gumbel\": true,\n    \"model/base_model_name\": \"FacebookAI/roberta-base\",\n    \"model/contrastive_temp\": 0.288440067739198,\n    \"model/distance_weightning\": \"none\",\n    \"model/dropout\": 0.1,\n    \"model/initial_gumbel_temp\": null,\n    \"model/is_decoder_model\": false,\n    \"model/min_gumbel_temp\": 0.5,\n    \"model/pooling_method\": \"li\",\n    \"model/use_softmax\": true\n  },\n  \"experiment_tag\": \"2_accumulate_grad_batches=4,betas=0_7_0_999,check_val_every_n_epoch=None,checkpoint_metric=val_total_loss,checkpoint_mode=min,device=gpu,early_stopping=False,early_stopping_metric=None,early_stopping_mode=None,early_stopping_patience=3,eps=0.0000,gradient_clip_val=None,lm_loss_weight=0.0000,log_every_n_steps=1,log_model=True,loss=info_nce,lr=0.0000,margin=None,max_epochs=4,max_steps=-1,num_cycles=0.5000,num_devices=3,precision=32,save_top_k=2,strategy=ddp_find_unused_parameters_true,use_wandb=True,val_check_interval=None,watch=gradients,weight_decay=0.0900,accumulate_grad_batches=4,betas=0_7_0_999,check_val_every_n_epoch=None,checkpoint_metric=val_total_loss,checkpoint_mode=min,device=gpu,early_stopping=False,early_stopping_metric=None,early_stopping_mode=None,early_stopping_patience=3,eps=0.0000,gradient_clip_val=None,lm_loss_weight=0.0000,log_every_n_steps=1,log_model=True,loss=info_nce,lr=0.0000,margin=None,max_epochs=4,max_steps=-1,num_cycles=0.5000,num_devices=3,precision=32,save_top_k=2,strategy=ddp_find_unused_parameters_true,use_wandb=True,val_check_interval=None,watch=gradients,weight_decay=0.0900,accumulate_grad_batches=4,betas=0_7_0_999,device=gpu,eps=0.0000,gradient_clip_val=None,lm_loss_weight=0.0000,log_every_n_steps=1,loss=info_nce,lr=0.0000,margin=None,max_concurrent_trials=3,max_epochs=3,max_steps=-1,max_t=3,metric=val_total_loss,mode=min,num_cpus_per_trial=10,num_cycles=0.5000,num_devices_per_trial=1,num_samples=30,precision=32,time_budget_s=151200,use_wandb=True,weight_decay=0.0504,batch_size=16,config_name=None,ds_name=se,load_from_cache_file=True,map_batch_size=1000,max_length=512,mlm_collator=False,tokenizer_name=FacebookAI_roberta-base,do_test=False,do_train=True,group_name=tune-deepstylometry-512-se-default,mode=tune,add_linear_layers=True,alpha=0.4030,auto_anneal_gumbel=True,base_model_name=FacebookAI_roberta-base,contrastive_temp=0.2884,distance_weightning=none,dropout=0.1000,initial_gumbel_temp=None,is_decoder_model=False,min_gumbel_temp=0.5000,pooling_method=li,use_softmax=True,project_name=deep-stylometry\",\n  \"stopping_criterion\": {\n    \"completed_epoch\": 3\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740400000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"relative_logdir\": \"train_tune_4a24f8a5_2_accumulate_grad_batches=4,betas=0_7_0_999,check_val_every_n_epoch=None,checkpoint_metric=val_total_loss,chec_2025-07-14_18-00-48\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1752508858.8343415,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b018c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"fb014122\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"mode\": \"tune\",\n    \"project_name\": \"deep-stylometry\",\n    \"group_name\": \"tune-deepstylometry-512-se-default\",\n    \"do_train\": true,\n    \"do_test\": false,\n    \"_execution_config\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 4.73e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-09,\n      \"weight_decay\": 0.09,\n      \"num_cycles\": 0.5,\n      \"early_stopping\": false,\n      \"early_stopping_metric\": null,\n      \"early_stopping_mode\": null,\n      \"early_stopping_patience\": 3,\n      \"checkpoint_metric\": \"val_total_loss\",\n      \"checkpoint_mode\": \"min\",\n      \"save_top_k\": 2,\n      \"device\": \"gpu\",\n      \"num_devices\": 3,\n      \"strategy\": \"ddp_find_unused_parameters_true\",\n      \"max_steps\": -1,\n      \"max_epochs\": 4,\n      \"val_check_interval\": null,\n      \"check_val_every_n_epoch\": null,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"use_wandb\": true,\n      \"log_model\": true,\n      \"watch\": \"gradients\"\n    },\n    \"data\": {\n      \"ds_name\": \"se\",\n      \"batch_size\": 16,\n      \"tokenizer_name\": \"FacebookAI/roberta-base\",\n      \"max_length\": 512,\n      \"map_batch_size\": 1000,\n      \"load_from_cache_file\": true,\n      \"config_name\": null,\n      \"mlm_collator\": false\n    },\n    \"model\": {\n      \"base_model_name\": \"FacebookAI/roberta-base\",\n      \"is_decoder_model\": false,\n      \"add_linear_layers\": true,\n      \"dropout\": 0.1,\n      \"contrastive_temp\": 0.5289768692764295,\n      \"pooling_method\": \"li\",\n      \"distance_weightning\": \"none\",\n      \"alpha\": 0.8426638321319679,\n      \"use_softmax\": true,\n      \"initial_gumbel_temp\": 1.0,\n      \"auto_anneal_gumbel\": true,\n      \"min_gumbel_temp\": 0.5\n    },\n    \"_train\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 4.73e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-09,\n      \"weight_decay\": 0.09,\n      \"num_cycles\": 0.5,\n      \"early_stopping\": false,\n      \"early_stopping_metric\": null,\n      \"early_stopping_mode\": null,\n      \"early_stopping_patience\": 3,\n      \"checkpoint_metric\": \"val_total_loss\",\n      \"checkpoint_mode\": \"min\",\n      \"save_top_k\": 2,\n      \"device\": \"gpu\",\n      \"num_devices\": 3,\n      \"strategy\": \"ddp_find_unused_parameters_true\",\n      \"max_steps\": -1,\n      \"max_epochs\": 4,\n      \"val_check_interval\": null,\n      \"check_val_every_n_epoch\": null,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"use_wandb\": true,\n      \"log_model\": true,\n      \"watch\": \"gradients\"\n    },\n    \"_tune\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 1.0333258751032523e-05,\n      \"betas\": [\n        0.8,\n        0.999\n      ],\n      \"eps\": 1e-07,\n      \"weight_decay\": 0.02061817204803445,\n      \"num_cycles\": 0.5,\n      \"device\": \"gpu\",\n      \"num_devices_per_trial\": 1,\n      \"num_cpus_per_trial\": 10,\n      \"max_steps\": -1,\n      \"max_epochs\": 3,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"metric\": \"val_total_loss\",\n      \"mode\": \"min\",\n      \"num_samples\": 30,\n      \"max_concurrent_trials\": 3,\n      \"time_budget_s\": 151200,\n      \"max_t\": 3,\n      \"use_wandb\": true\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"mode\": \"tune\",\n    \"project_name\": \"deep-stylometry\",\n    \"group_name\": \"tune-deepstylometry-512-se-default\",\n    \"do_train\": true,\n    \"do_test\": false,\n    \"_execution_config\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 4.73e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-09,\n      \"weight_decay\": 0.09,\n      \"num_cycles\": 0.5,\n      \"early_stopping\": false,\n      \"early_stopping_metric\": null,\n      \"early_stopping_mode\": null,\n      \"early_stopping_patience\": 3,\n      \"checkpoint_metric\": \"val_total_loss\",\n      \"checkpoint_mode\": \"min\",\n      \"save_top_k\": 2,\n      \"device\": \"gpu\",\n      \"num_devices\": 3,\n      \"strategy\": \"ddp_find_unused_parameters_true\",\n      \"max_steps\": -1,\n      \"max_epochs\": 4,\n      \"val_check_interval\": null,\n      \"check_val_every_n_epoch\": null,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"use_wandb\": true,\n      \"log_model\": true,\n      \"watch\": \"gradients\"\n    },\n    \"data\": {\n      \"ds_name\": \"se\",\n      \"batch_size\": 16,\n      \"tokenizer_name\": \"FacebookAI/roberta-base\",\n      \"max_length\": 512,\n      \"map_batch_size\": 1000,\n      \"load_from_cache_file\": true,\n      \"config_name\": null,\n      \"mlm_collator\": false\n    },\n    \"model\": {\n      \"base_model_name\": \"FacebookAI/roberta-base\",\n      \"is_decoder_model\": false,\n      \"add_linear_layers\": true,\n      \"dropout\": 0.1,\n      \"contrastive_temp\": 0.5289768692764295,\n      \"pooling_method\": \"li\",\n      \"distance_weightning\": \"none\",\n      \"alpha\": 0.8426638321319679,\n      \"use_softmax\": true,\n      \"initial_gumbel_temp\": 1.0,\n      \"auto_anneal_gumbel\": true,\n      \"min_gumbel_temp\": 0.5\n    },\n    \"_train\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 4.73e-05,\n      \"betas\": [\n        0.7,\n        0.999\n      ],\n      \"eps\": 1e-09,\n      \"weight_decay\": 0.09,\n      \"num_cycles\": 0.5,\n      \"early_stopping\": false,\n      \"early_stopping_metric\": null,\n      \"early_stopping_mode\": null,\n      \"early_stopping_patience\": 3,\n      \"checkpoint_metric\": \"val_total_loss\",\n      \"checkpoint_mode\": \"min\",\n      \"save_top_k\": 2,\n      \"device\": \"gpu\",\n      \"num_devices\": 3,\n      \"strategy\": \"ddp_find_unused_parameters_true\",\n      \"max_steps\": -1,\n      \"max_epochs\": 4,\n      \"val_check_interval\": null,\n      \"check_val_every_n_epoch\": null,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"use_wandb\": true,\n      \"log_model\": true,\n      \"watch\": \"gradients\"\n    },\n    \"_tune\": {\n      \"loss\": \"info_nce\",\n      \"margin\": null,\n      \"lm_loss_weight\": 0.0,\n      \"lr\": 1.0333258751032523e-05,\n      \"betas\": [\n        0.8,\n        0.999\n      ],\n      \"eps\": 1e-07,\n      \"weight_decay\": 0.02061817204803445,\n      \"num_cycles\": 0.5,\n      \"device\": \"gpu\",\n      \"num_devices_per_trial\": 1,\n      \"num_cpus_per_trial\": 10,\n      \"max_steps\": -1,\n      \"max_epochs\": 3,\n      \"log_every_n_steps\": 1,\n      \"accumulate_grad_batches\": 4,\n      \"gradient_clip_val\": null,\n      \"precision\": \"32\",\n      \"metric\": \"val_total_loss\",\n      \"mode\": \"min\",\n      \"num_samples\": 30,\n      \"max_concurrent_trials\": 3,\n      \"time_budget_s\": 151200,\n      \"max_t\": 3,\n      \"use_wandb\": true\n    }\n  },\n  \"evaluated_params\": {\n    \"do_test\": false,\n    \"do_train\": true,\n    \"group_name\": \"tune-deepstylometry-512-se-default\",\n    \"mode\": \"tune\",\n    \"project_name\": \"deep-stylometry\",\n    \"_execution_config/accumulate_grad_batches\": 4,\n    \"_execution_config/betas\": [\n      0.7,\n      0.999\n    ],\n    \"_execution_config/check_val_every_n_epoch\": null,\n    \"_execution_config/checkpoint_metric\": \"val_total_loss\",\n    \"_execution_config/checkpoint_mode\": \"min\",\n    \"_execution_config/device\": \"gpu\",\n    \"_execution_config/early_stopping\": false,\n    \"_execution_config/early_stopping_metric\": null,\n    \"_execution_config/early_stopping_mode\": null,\n    \"_execution_config/early_stopping_patience\": 3,\n    \"_execution_config/eps\": 1e-09,\n    \"_execution_config/gradient_clip_val\": null,\n    \"_execution_config/lm_loss_weight\": 0.0,\n    \"_execution_config/log_every_n_steps\": 1,\n    \"_execution_config/log_model\": true,\n    \"_execution_config/loss\": \"info_nce\",\n    \"_execution_config/lr\": 4.73e-05,\n    \"_execution_config/margin\": null,\n    \"_execution_config/max_epochs\": 4,\n    \"_execution_config/max_steps\": -1,\n    \"_execution_config/num_cycles\": 0.5,\n    \"_execution_config/num_devices\": 3,\n    \"_execution_config/precision\": \"32\",\n    \"_execution_config/save_top_k\": 2,\n    \"_execution_config/strategy\": \"ddp_find_unused_parameters_true\",\n    \"_execution_config/use_wandb\": true,\n    \"_execution_config/val_check_interval\": null,\n    \"_execution_config/watch\": \"gradients\",\n    \"_execution_config/weight_decay\": 0.09,\n    \"_train/accumulate_grad_batches\": 4,\n    \"_train/betas\": [\n      0.7,\n      0.999\n    ],\n    \"_train/check_val_every_n_epoch\": null,\n    \"_train/checkpoint_metric\": \"val_total_loss\",\n    \"_train/checkpoint_mode\": \"min\",\n    \"_train/device\": \"gpu\",\n    \"_train/early_stopping\": false,\n    \"_train/early_stopping_metric\": null,\n    \"_train/early_stopping_mode\": null,\n    \"_train/early_stopping_patience\": 3,\n    \"_train/eps\": 1e-09,\n    \"_train/gradient_clip_val\": null,\n    \"_train/lm_loss_weight\": 0.0,\n    \"_train/log_every_n_steps\": 1,\n    \"_train/log_model\": true,\n    \"_train/loss\": \"info_nce\",\n    \"_train/lr\": 4.73e-05,\n    \"_train/margin\": null,\n    \"_train/max_epochs\": 4,\n    \"_train/max_steps\": -1,\n    \"_train/num_cycles\": 0.5,\n    \"_train/num_devices\": 3,\n    \"_train/precision\": \"32\",\n    \"_train/save_top_k\": 2,\n    \"_train/strategy\": \"ddp_find_unused_parameters_true\",\n    \"_train/use_wandb\": true,\n    \"_train/val_check_interval\": null,\n    \"_train/watch\": \"gradients\",\n    \"_train/weight_decay\": 0.09,\n    \"_tune/accumulate_grad_batches\": 4,\n    \"_tune/betas\": [\n      0.8,\n      0.999\n    ],\n    \"_tune/device\": \"gpu\",\n    \"_tune/eps\": 1e-07,\n    \"_tune/gradient_clip_val\": null,\n    \"_tune/lm_loss_weight\": 0.0,\n    \"_tune/log_every_n_steps\": 1,\n    \"_tune/loss\": \"info_nce\",\n    \"_tune/lr\": 1.0333258751032523e-05,\n    \"_tune/margin\": null,\n    \"_tune/max_concurrent_trials\": 3,\n    \"_tune/max_epochs\": 3,\n    \"_tune/max_steps\": -1,\n    \"_tune/max_t\": 3,\n    \"_tune/metric\": \"val_total_loss\",\n    \"_tune/mode\": \"min\",\n    \"_tune/num_cpus_per_trial\": 10,\n    \"_tune/num_cycles\": 0.5,\n    \"_tune/num_devices_per_trial\": 1,\n    \"_tune/num_samples\": 30,\n    \"_tune/precision\": \"32\",\n    \"_tune/time_budget_s\": 151200,\n    \"_tune/use_wandb\": true,\n    \"_tune/weight_decay\": 0.02061817204803445,\n    \"data/batch_size\": 16,\n    \"data/config_name\": null,\n    \"data/ds_name\": \"se\",\n    \"data/load_from_cache_file\": true,\n    \"data/map_batch_size\": 1000,\n    \"data/max_length\": 512,\n    \"data/mlm_collator\": false,\n    \"data/tokenizer_name\": \"FacebookAI/roberta-base\",\n    \"model/add_linear_layers\": true,\n    \"model/alpha\": 0.8426638321319679,\n    \"model/auto_anneal_gumbel\": true,\n    \"model/base_model_name\": \"FacebookAI/roberta-base\",\n    \"model/contrastive_temp\": 0.5289768692764295,\n    \"model/distance_weightning\": \"none\",\n    \"model/dropout\": 0.1,\n    \"model/initial_gumbel_temp\": 1.0,\n    \"model/is_decoder_model\": false,\n    \"model/min_gumbel_temp\": 0.5,\n    \"model/pooling_method\": \"li\",\n    \"model/use_softmax\": true\n  },\n  \"experiment_tag\": \"3_accumulate_grad_batches=4,betas=0_7_0_999,check_val_every_n_epoch=None,checkpoint_metric=val_total_loss,checkpoint_mode=min,device=gpu,early_stopping=False,early_stopping_metric=None,early_stopping_mode=None,early_stopping_patience=3,eps=0.0000,gradient_clip_val=None,lm_loss_weight=0.0000,log_every_n_steps=1,log_model=True,loss=info_nce,lr=0.0000,margin=None,max_epochs=4,max_steps=-1,num_cycles=0.5000,num_devices=3,precision=32,save_top_k=2,strategy=ddp_find_unused_parameters_true,use_wandb=True,val_check_interval=None,watch=gradients,weight_decay=0.0900,accumulate_grad_batches=4,betas=0_7_0_999,check_val_every_n_epoch=None,checkpoint_metric=val_total_loss,checkpoint_mode=min,device=gpu,early_stopping=False,early_stopping_metric=None,early_stopping_mode=None,early_stopping_patience=3,eps=0.0000,gradient_clip_val=None,lm_loss_weight=0.0000,log_every_n_steps=1,log_model=True,loss=info_nce,lr=0.0000,margin=None,max_epochs=4,max_steps=-1,num_cycles=0.5000,num_devices=3,precision=32,save_top_k=2,strategy=ddp_find_unused_parameters_true,use_wandb=True,val_check_interval=None,watch=gradients,weight_decay=0.0900,accumulate_grad_batches=4,betas=0_8_0_999,device=gpu,eps=0.0000,gradient_clip_val=None,lm_loss_weight=0.0000,log_every_n_steps=1,loss=info_nce,lr=0.0000,margin=None,max_concurrent_trials=3,max_epochs=3,max_steps=-1,max_t=3,metric=val_total_loss,mode=min,num_cpus_per_trial=10,num_cycles=0.5000,num_devices_per_trial=1,num_samples=30,precision=32,time_budget_s=151200,use_wandb=True,weight_decay=0.0206,batch_size=16,config_name=None,ds_name=se,load_from_cache_file=True,map_batch_size=1000,max_length=512,mlm_collator=False,tokenizer_name=FacebookAI_roberta-base,do_test=False,do_train=True,group_name=tune-deepstylometry-512-se-default,mode=tune,add_linear_layers=True,alpha=0.8427,auto_anneal_gumbel=True,base_model_name=FacebookAI_roberta-base,contrastive_temp=0.5290,distance_weightning=none,dropout=0.1000,initial_gumbel_temp=1.0000,is_decoder_model=False,min_gumbel_temp=0.5000,pooling_method=li,use_softmax=True,project_name=deep-stylometry\",\n  \"stopping_criterion\": {\n    \"completed_epoch\": 3\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740400000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"train_tune_fb014122_3_accumulate_grad_batches=4,betas=0_7_0_999,check_val_every_n_epoch=None,checkpoint_metric=val_total_loss,chec_2025-07-14_18-00-58\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"trial_id\": \"fb014122\"\n  },\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b018c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"]], "runner_data": {"_earliest_stopping_actor": Infinity, "_actor_cleanup_timeout": 600, "_actor_force_cleanup_timeout": 10, "_reuse_actors": false, "_buffer_length": 1, "_buffer_min_time_s": 0.0, "_buffer_max_time_s": 100.0, "_max_pending_trials": 1, "_metric": "auroc", "_total_time": 0, "_iteration": 5495, "_has_errored": false, "_fail_fast": true, "_print_trial_errors": true, "_cached_trial_decisions": {}, "_queued_trial_decisions": {}, "_should_stop_experiment": false, "_stopper": {"_type": "CLOUDPICKLE_FALLBACK", "value": "80059579000000000000008c187261792e74756e652e73746f707065722e74696d656f7574948c0e54696d656f757453746f707065729493942981947d94288c105f74696d656f75745f7365636f6e6473944aa04e02008c075f6275646765749447410263b1985340008c0b5f6c6173745f636865636b944741da1d4af3c5df8d75622e"}, "_start_time": 1752508836.9880083, "_session_str": "2025-07-14_18-00-36", "_checkpoint_period": "auto", "_trial_checkpoint_config": {"_type": "CLOUDPICKLE_FALLBACK", "value": "800595f2000000000000008c087261792e74756e65948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b018c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394680c75622e"}, "_resumed": false}, "stats": {"start_time": 1752508836.9880083}}