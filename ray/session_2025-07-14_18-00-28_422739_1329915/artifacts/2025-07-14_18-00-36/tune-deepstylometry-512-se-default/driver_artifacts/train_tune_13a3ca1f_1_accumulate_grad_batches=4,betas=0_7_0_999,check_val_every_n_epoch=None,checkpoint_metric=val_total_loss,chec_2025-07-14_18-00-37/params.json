{
  "_execution_config": {
    "accumulate_grad_batches": 4,
    "betas": [
      0.7,
      0.999
    ],
    "check_val_every_n_epoch": null,
    "checkpoint_metric": "val_total_loss",
    "checkpoint_mode": "min",
    "device": "gpu",
    "early_stopping": false,
    "early_stopping_metric": null,
    "early_stopping_mode": null,
    "early_stopping_patience": 3,
    "eps": 1e-09,
    "gradient_clip_val": null,
    "lm_loss_weight": 0.0,
    "log_every_n_steps": 1,
    "log_model": true,
    "loss": "info_nce",
    "lr": 4.73e-05,
    "margin": null,
    "max_epochs": 4,
    "max_steps": -1,
    "num_cycles": 0.5,
    "num_devices": 3,
    "precision": "32",
    "save_top_k": 2,
    "strategy": "ddp_find_unused_parameters_true",
    "use_wandb": true,
    "val_check_interval": null,
    "watch": "gradients",
    "weight_decay": 0.09
  },
  "_train": {
    "accumulate_grad_batches": 4,
    "betas": [
      0.7,
      0.999
    ],
    "check_val_every_n_epoch": null,
    "checkpoint_metric": "val_total_loss",
    "checkpoint_mode": "min",
    "device": "gpu",
    "early_stopping": false,
    "early_stopping_metric": null,
    "early_stopping_mode": null,
    "early_stopping_patience": 3,
    "eps": 1e-09,
    "gradient_clip_val": null,
    "lm_loss_weight": 0.0,
    "log_every_n_steps": 1,
    "log_model": true,
    "loss": "info_nce",
    "lr": 4.73e-05,
    "margin": null,
    "max_epochs": 4,
    "max_steps": -1,
    "num_cycles": 0.5,
    "num_devices": 3,
    "precision": "32",
    "save_top_k": 2,
    "strategy": "ddp_find_unused_parameters_true",
    "use_wandb": true,
    "val_check_interval": null,
    "watch": "gradients",
    "weight_decay": 0.09
  },
  "_tune": {
    "accumulate_grad_batches": 4,
    "betas": [
      0.7,
      0.999
    ],
    "device": "gpu",
    "eps": 1e-07,
    "gradient_clip_val": null,
    "lm_loss_weight": 0.0,
    "log_every_n_steps": 1,
    "loss": "info_nce",
    "lr": 7.871594481686971e-05,
    "margin": null,
    "max_concurrent_trials": 3,
    "max_epochs": 3,
    "max_steps": -1,
    "max_t": 3,
    "metric": "val_total_loss",
    "mode": "min",
    "num_cpus_per_trial": 10,
    "num_cycles": 0.5,
    "num_devices_per_trial": 1,
    "num_samples": 30,
    "precision": "32",
    "time_budget_s": 151200,
    "use_wandb": true,
    "weight_decay": 0.08429170041256055
  },
  "data": {
    "batch_size": 16,
    "config_name": null,
    "ds_name": "se",
    "load_from_cache_file": true,
    "map_batch_size": 1000,
    "max_length": 512,
    "mlm_collator": false,
    "tokenizer_name": "FacebookAI/roberta-base"
  },
  "do_test": false,
  "do_train": true,
  "group_name": "tune-deepstylometry-512-se-default",
  "mode": "tune",
  "model": {
    "add_linear_layers": true,
    "alpha": 0.32436397316385956,
    "auto_anneal_gumbel": true,
    "base_model_name": "FacebookAI/roberta-base",
    "contrastive_temp": 0.27922426342871626,
    "distance_weightning": "exp",
    "dropout": 0.1,
    "initial_gumbel_temp": null,
    "is_decoder_model": false,
    "min_gumbel_temp": 0.5,
    "pooling_method": "li",
    "use_softmax": true
  },
  "project_name": "deep-stylometry"
}